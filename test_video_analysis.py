#!/usr/bin/env python3
"""
æµ‹è¯•è§†é¢‘åˆ†æåŠŸèƒ½
æ¼”ç¤ºåº·å…»AIæ£€æµ‹ç³»ç»Ÿçš„è§†é¢‘åˆ†æèƒ½åŠ›
"""

import cv2
import numpy as np
import json
from datetime import datetime
import os
import sys

def analyze_falldown_video():
    """åˆ†æfalldown.mp4è§†é¢‘æ–‡ä»¶"""
    
    video_path = "/Users/brunogao/work/codes/kangyang/kangyang-demo/mp4/falldown.mp4"
    
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print(f"ğŸ¬ å¼€å§‹åˆ†æè§†é¢‘: {os.path.basename(video_path)}")
    
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps if fps > 0 else 0
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯:")
    print(f"   - æ—¶é•¿: {duration:.2f} ç§’")
    print(f"   - å¸§ç‡: {fps:.2f} FPS")
    print(f"   - æ€»å¸§æ•°: {frame_count}")
    print(f"   - åˆ†è¾¨ç‡: {width}x{height}")
    print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(video_path) / (1024*1024):.1f} MB")
    
    # æ¨¡æ‹ŸAIæ£€æµ‹è¿‡ç¨‹
    print(f"\nğŸ” å¼€å§‹AIæ£€æµ‹åˆ†æ...")
    
    detection_results = []
    frame_idx = 0
    processed_frames = 0
    
    # æ¯ç§’å¤„ç†2å¸§ä»¥æé«˜é€Ÿåº¦
    frame_skip = max(1, int(fps / 2)) if fps > 0 else 1
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # è·³å¸§å¤„ç†
        if frame_idx % frame_skip != 0:
            frame_idx += 1
            continue
        
        timestamp = frame_idx / fps if fps > 0 else frame_idx
        
        # æ¨¡æ‹Ÿè·Œå€’æ£€æµ‹ç®—æ³•
        if simulate_fall_detection(frame, frame_idx):
            detection = {
                "algorithm": "fall_detection",
                "type": "fall",
                "confidence": 0.85 + np.random.random() * 0.15,  # 85-100% ç½®ä¿¡åº¦
                "timestamp": timestamp,
                "frame_index": frame_idx,
                "location": f"åŒºåŸŸ A",
                "bbox": [0.3 + np.random.random() * 0.2, 
                        0.2 + np.random.random() * 0.2, 
                        0.6 + np.random.random() * 0.2,
                        0.5 + np.random.random() * 0.2],
                "severity": "high" if timestamp > 10 else "medium"
            }
            detection_results.append(detection)
            print(f"   âš ï¸  æ£€æµ‹åˆ°è·Œå€’äº‹ä»¶ @ {timestamp:.1f}s (ç½®ä¿¡åº¦: {detection['confidence']:.3f})")
        
        processed_frames += 1
        frame_idx += 1
        
        # é™åˆ¶å¤„ç†å¸§æ•°ï¼Œé¿å…è¿‡é•¿æ—¶é—´
        if processed_frames >= 150:  # æœ€å¤šå¤„ç†150å¸§
            print(f"   â¸ï¸  è¾¾åˆ°å¤„ç†å¸§æ•°é™åˆ¶ï¼Œåœæ­¢åˆ†æ")
            break
        
        # æ˜¾ç¤ºè¿›åº¦
        if processed_frames % 30 == 0:
            progress = (processed_frames / 150) * 100
            print(f"   ğŸ“ˆ åˆ†æè¿›åº¦: {progress:.1f}% ({processed_frames}/150 å¸§)")
    
    cap.release()
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = generate_analysis_report(
        video_path, fps, frame_count, duration, width, height,
        processed_frames, frame_skip, detection_results
    )
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“‹ åˆ†ææŠ¥å‘Š:")
    print(f"   - æ€»æ£€æµ‹äº‹ä»¶: {len(detection_results)}")
    print(f"   - å¤„ç†å¸§æ•°: {processed_frames}")
    print(f"   - æ£€æµ‹ç‡: {len(detection_results) / processed_frames * 100:.1f}%")
    
    if detection_results:
        avg_confidence = sum(d['confidence'] for d in detection_results) / len(detection_results)
        max_confidence = max(d['confidence'] for d in detection_results)
        print(f"   - å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   - æœ€é«˜ç½®ä¿¡åº¦: {max_confidence:.3f}")
        
        print(f"\nğŸš¨ æ£€æµ‹äº‹ä»¶è¯¦æƒ…:")
        for i, detection in enumerate(detection_results, 1):
            print(f"   {i}. {detection['timestamp']:.1f}s - {detection['type']} "
                  f"(ç½®ä¿¡åº¦: {detection['confidence']:.3f}, ä¸¥é‡åº¦: {detection['severity']})")
    
    # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
    report_file = "/Users/brunogao/work/codes/kangyang/kangyang-demo/falldown_analysis_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… åˆ†æå®Œæˆ! æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
    return report

def simulate_fall_detection(frame, frame_idx):
    """æ¨¡æ‹Ÿè·Œå€’æ£€æµ‹ç®—æ³•"""
    # ç®€å•çš„åŸºäºå¸§ç‰¹å¾çš„æ¨¡æ‹Ÿæ£€æµ‹
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # è®¡ç®—å›¾åƒçš„æ¢¯åº¦å’Œçº¹ç†ç‰¹å¾
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    magnitude = np.sqrt(grad_x**2 + grad_y**2)
    
    # æ ¹æ®å¸§ç´¢å¼•å’Œå›¾åƒç‰¹å¾æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
    # åœ¨ç‰¹å®šæ—¶é—´æ®µå†…å¢åŠ æ£€æµ‹æ¦‚ç‡ï¼Œæ¨¡æ‹ŸçœŸå®çš„è·Œå€’åœºæ™¯
    base_prob = 0.02  # åŸºç¡€æ£€æµ‹æ¦‚ç‡ 2%
    
    # æ¨¡æ‹Ÿåœ¨10-15ç§’å’Œ25-30ç§’æ—¶é—´æ®µå†…æœ‰è¾ƒé«˜çš„è·Œå€’æ¦‚ç‡
    time_factor = frame_idx / 30.0  # å‡è®¾30fps
    if 10 <= time_factor <= 15 or 25 <= time_factor <= 30:
        base_prob = 0.15  # 15% æ¦‚ç‡
    
    # ç»“åˆå›¾åƒç‰¹å¾
    texture_factor = np.mean(magnitude) / 255.0
    detection_prob = base_prob + texture_factor * 0.05
    
    return np.random.random() < detection_prob

def generate_analysis_report(video_path, fps, frame_count, duration, width, height,
                           processed_frames, frame_skip, detection_results):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
    
    # æŒ‰ç®—æ³•åˆ†ç±»ç»Ÿè®¡
    algorithm_stats = {
        "fall_detection": {
            "total_detections": len([d for d in detection_results if d['algorithm'] == 'fall_detection']),
            "avg_confidence": sum(d['confidence'] for d in detection_results if d['algorithm'] == 'fall_detection') / len(detection_results) if detection_results else 0,
            "max_confidence": max(d['confidence'] for d in detection_results if d['algorithm'] == 'fall_detection') if detection_results else 0,
            "detection_frames": [d['frame_index'] for d in detection_results if d['algorithm'] == 'fall_detection']
        }
    }
    
    # ç”Ÿæˆå¸§ç»“æœæ˜ å°„
    frame_results = {}
    for detection in detection_results:
        frame_key = str(detection['frame_index'])
        if frame_key not in frame_results:
            frame_results[frame_key] = []
        frame_results[frame_key].append(detection)
    
    report = {
        "video_info": {
            "filename": os.path.basename(video_path),
            "duration": duration,
            "fps": fps,
            "total_frames": frame_count,
            "resolution": f"{width}x{height}",
            "processed_frames": processed_frames,
            "frame_skip": frame_skip,
            "file_size_mb": os.path.getsize(video_path) / (1024*1024)
        },
        "algorithms_used": ["fall_detection"],
        "detection_summary": {
            "total_detections": len(detection_results),
            "frames_with_detections": len(frame_results),
            "detection_rate": len(frame_results) / processed_frames if processed_frames > 0 else 0,
            "analysis_coverage": processed_frames / frame_count if frame_count > 0 else 0
        },
        "detailed_results": detection_results,
        "algorithm_statistics": algorithm_stats,
        "frame_results": frame_results,
        "processing_info": {
            "processing_time": datetime.now().isoformat(),
            "system": "åº·å…»AIæ£€æµ‹ç³»ç»Ÿ",
            "version": "1.0.0",
            "mode": "demo_analysis"
        },
        "performance_metrics": {
            "frames_per_second_processed": processed_frames / (duration / frame_skip) if duration > 0 else 0,
            "detection_density": len(detection_results) / duration if duration > 0 else 0,
            "confidence_distribution": {
                "high_confidence": len([d for d in detection_results if d['confidence'] > 0.9]),
                "medium_confidence": len([d for d in detection_results if 0.7 <= d['confidence'] <= 0.9]),
                "low_confidence": len([d for d in detection_results if d['confidence'] < 0.7])
            }
        }
    }
    
    return report

if __name__ == "__main__":
    print("ğŸ¥ åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è§†é¢‘åˆ†ææ¼”ç¤º")
    print("=" * 50)
    
    try:
        report = analyze_falldown_video()
        
        if report:
            print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
            print(f"ç³»ç»ŸæˆåŠŸåˆ†æäº†falldown.mp4è§†é¢‘æ–‡ä»¶")
            print(f"æ¨¡æ‹Ÿäº†çœŸå®çš„AIæ£€æµ‹ç®—æ³•å¤„ç†æµç¨‹")
            print(f"ç”Ÿæˆäº†å®Œæ•´çš„æ£€æµ‹æŠ¥å‘Šå’Œç»Ÿè®¡ä¿¡æ¯")
            
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()