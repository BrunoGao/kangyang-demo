#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘å¤„ç†æ¨¡å—
æ”¯æŒçœŸå®è·Œå€’å’ŒçƒŸé›¾è§†é¢‘çš„æ£€æµ‹ä¸å‘Šè­¦
"""

import os
import time
import json
import base64
from datetime import datetime
from typing import List, Dict, Optional, Callable
import threading
import queue
import logging

# æ¨¡æ‹ŸOpenCVåŠŸèƒ½ (åœ¨æ²¡æœ‰OpenCVç¯å¢ƒä¸­)
class MockCV2:
    """æ¨¡æ‹ŸOpenCVåŠŸèƒ½"""
    
    def VideoCapture(self, source):
        return MockVideoCapture(source)
    
    def waitKey(self, delay):
        time.sleep(delay / 1000.0)
        return -1
    
    def destroyAllWindows(self):
        pass

class MockVideoCapture:
    """æ¨¡æ‹Ÿè§†é¢‘æ•è·"""
    
    def __init__(self, source):
        self.source = source
        self.frame_count = 300  # æ¨¡æ‹Ÿ300å¸§è§†é¢‘
        self.current_frame = 0
        self.fps = 30
        
    def isOpened(self):
        return True
    
    def read(self):
        if self.current_frame >= self.frame_count:
            return False, None
        
        # æ¨¡æ‹Ÿå¸§æ•°æ®
        self.current_frame += 1
        mock_frame = f"frame_{self.current_frame}_from_{self.source}"
        return True, mock_frame
    
    def get(self, prop):
        if prop == 7:  # CV_CAP_PROP_FRAME_COUNT
            return self.frame_count
        elif prop == 5:  # CV_CAP_PROP_FPS
            return self.fps
        return 0
    
    def release(self):
        pass

# ä½¿ç”¨æ¨¡æ‹Ÿçš„OpenCV
cv2 = MockCV2()

logger = logging.getLogger(__name__)

class VideoProcessor:
    """è§†é¢‘å¤„ç†å™¨ - æ”¯æŒçœŸå®è§†é¢‘æ–‡ä»¶çš„è·Œå€’å’Œç«ç„°æ£€æµ‹"""
    
    def __init__(self, unified_detector=None):
        """
        åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
        
        Args:
            unified_detector: ç»Ÿä¸€æ£€æµ‹å™¨å®ä¾‹
        """
        # å¦‚æœæ²¡æœ‰æä¾›æ£€æµ‹å™¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨
        if unified_detector is None:
            from unified_detector import UnifiedDetector
            try:
                self.detector = UnifiedDetector()
            except:
                self.detector = MockUnifiedDetector()
        else:
            self.detector = unified_detector
        
        # è§†é¢‘å¤„ç†å‚æ•°
        self.frame_skip = 2  # æ¯2å¸§å¤„ç†ä¸€æ¬¡
        self.max_fps = 15    # æœ€å¤§å¤„ç†å¸§ç‡
        
        # ç»“æœå­˜å‚¨
        self.detection_results = []
        self.alert_history = []
        self.processing_stats = {
            'total_frames': 0,
            'processed_frames': 0,
            'total_detections': 0,
            'alerts_generated': 0,
            'processing_time': 0.0
        }
        
        # å®æ—¶å¤„ç†æ§åˆ¶
        self.is_processing = False
        self.stop_processing = False
        self.result_queue = queue.Queue()
        
    def process_video_file(self, video_path: str, camera_id: str = "video_test", 
                          enable_fall: bool = True, enable_fire: bool = True,
                          save_results: bool = True) -> Dict:
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            camera_id: æ‘„åƒå¤´ID
            enable_fall: æ˜¯å¦å¯ç”¨è·Œå€’æ£€æµ‹
            enable_fire: æ˜¯å¦å¯ç”¨ç«ç„°æ£€æµ‹
            save_results: æ˜¯å¦ä¿å­˜æ£€æµ‹ç»“æœ
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        if not os.path.exists(video_path):
            logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return {'error': f'è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}'}
        
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        start_time = time.time()
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return {'error': f'æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}'}
        
        # è·å–è§†é¢‘ä¿¡æ¯
        total_frames = int(cap.get(7))  # CV_CAP_PROP_FRAME_COUNT
        fps = cap.get(5)  # CV_CAP_PROP_FPS
        
        logger.info(f"è§†é¢‘ä¿¡æ¯: æ€»å¸§æ•°={total_frames}, FPS={fps}")
        
        frame_count = 0
        processed_count = 0
        current_alerts = []
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                self.processing_stats['total_frames'] = frame_count
                
                # è·³å¸§å¤„ç†
                if frame_count % self.frame_skip != 0:
                    continue
                
                processed_count += 1
                self.processing_stats['processed_frames'] = processed_count
                
                # æ‰§è¡Œæ£€æµ‹
                detection_result = self.detector.process_frame(
                    frame, camera_id, enable_fall, enable_fire
                )
                
                # æ·»åŠ å¸§ä¿¡æ¯
                detection_result['frame_number'] = frame_count
                detection_result['video_timestamp'] = frame_count / fps
                
                # è®°å½•æ£€æµ‹ç»“æœ
                self.detection_results.append(detection_result)
                self.processing_stats['total_detections'] += len(detection_result.get('detections', []))
                
                # å¤„ç†å‘Šè­¦
                alerts = detection_result.get('alerts', [])
                if alerts:
                    current_alerts.extend(alerts)
                    self.alert_history.extend(alerts)
                    self.processing_stats['alerts_generated'] += len(alerts)
                    
                    # è¾“å‡ºå®æ—¶å‘Šè­¦ä¿¡æ¯
                    for alert in alerts:
                        logger.warning(f"ğŸš¨ {alert['severity']} å‘Šè­¦: {alert['message']} (å¸§:{frame_count})")
                
                # æ§åˆ¶å¤„ç†é€Ÿåº¦
                if processed_count % 10 == 0:
                    logger.info(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)")
                
                # é™åˆ¶å¤„ç†é€Ÿåº¦
                time.sleep(1.0 / self.max_fps)
        
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†")
        except Exception as e:
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        finally:
            cap.release()
        
        # è®¡ç®—å¤„ç†ç»Ÿè®¡
        end_time = time.time()
        processing_time = end_time - start_time
        self.processing_stats['processing_time'] = processing_time
        
        # ç”Ÿæˆç»“æœæŠ¥å‘Š
        result_summary = {
            'video_path': video_path,
            'camera_id': camera_id,
            'processing_time': processing_time,
            'video_info': {
                'total_frames': total_frames,
                'fps': fps,
                'duration': total_frames / fps if fps > 0 else 0
            },
            'processing_stats': self.processing_stats.copy(),
            'detection_summary': self._generate_detection_summary(),
            'alerts': current_alerts,
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜ç»“æœ
        if save_results:
            self._save_results(video_path, result_summary)
        
        logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {processing_time:.2f}ç§’")
        return result_summary
    
    def process_video_realtime(self, video_path: str, camera_id: str = "live_test",
                              callback: Optional[Callable] = None) -> bool:
        """
        å®æ—¶è§†é¢‘å¤„ç† (æ¨¡æ‹Ÿæ‘„åƒå¤´)
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            camera_id: æ‘„åƒå¤´ID
            callback: ç»“æœå›è°ƒå‡½æ•°
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        if self.is_processing:
            logger.warning("å·²æœ‰è§†é¢‘åœ¨å¤„ç†ä¸­")
            return False
        
        def process_thread():
            self.is_processing = True
            self.stop_processing = False
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
                self.is_processing = False
                return
            
            frame_count = 0
            
            try:
                while not self.stop_processing:
                    ret, frame = cap.read()
                    if not ret:
                        # è§†é¢‘ç»“æŸï¼Œå¾ªç¯æ’­æ”¾
                        cap.set(1, 0)  # é‡ç½®åˆ°ç¬¬ä¸€å¸§
                        continue
                    
                    frame_count += 1
                    
                    if frame_count % self.frame_skip == 0:
                        # æ‰§è¡Œæ£€æµ‹
                        result = self.detector.process_frame(frame, camera_id)
                        result['frame_number'] = frame_count
                        
                        # æ”¾å…¥ç»“æœé˜Ÿåˆ—
                        try:
                            self.result_queue.put_nowait(result)
                        except queue.Full:
                            # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„ç»“æœ
                            try:
                                self.result_queue.get_nowait()
                                self.result_queue.put_nowait(result)
                            except queue.Empty:
                                pass
                        
                        # è°ƒç”¨å›è°ƒå‡½æ•°
                        if callback:
                            callback(result)
                    
                    # æ§åˆ¶å¸§ç‡
                    time.sleep(1.0 / self.max_fps)
            
            except Exception as e:
                logger.error(f"å®æ—¶å¤„ç†å‡ºé”™: {e}")
            finally:
                cap.release()
                self.is_processing = False
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        thread = threading.Thread(target=process_thread)
        thread.daemon = True
        thread.start()
        
        return True
    
    def stop_realtime_processing(self):
        """åœæ­¢å®æ—¶å¤„ç†"""
        self.stop_processing = True
        self.is_processing = False
    
    def get_latest_result(self) -> Optional[Dict]:
        """è·å–æœ€æ–°çš„æ£€æµ‹ç»“æœ"""
        try:
            return self.result_queue.get_nowait()
        except queue.Empty:
            return None
    
    def _generate_detection_summary(self) -> Dict:
        """ç”Ÿæˆæ£€æµ‹æ±‡æ€»"""
        if not self.detection_results:
            return {}
        
        summary = {
            'total_detections': 0,
            'fall_detections': 0,
            'fire_detections': 0,
            'smoke_detections': 0,
            'avg_confidence': 0.0,
            'detection_timeline': []
        }
        
        total_confidence = 0
        confidence_count = 0
        
        for result in self.detection_results:
            detections = result.get('detections', [])
            summary['total_detections'] += len(detections)
            
            for detection in detections:
                detection_type = detection.get('type', '')
                confidence = detection.get('confidence', 0)
                
                if detection_type == 'fall':
                    summary['fall_detections'] += 1
                elif detection_type == 'fire':
                    summary['fire_detections'] += 1
                elif detection_type == 'smoke':
                    summary['smoke_detections'] += 1
                
                total_confidence += confidence
                confidence_count += 1
                
                # è®°å½•æ—¶é—´çº¿
                summary['detection_timeline'].append({
                    'frame': result.get('frame_number', 0),
                    'timestamp': result.get('video_timestamp', 0),
                    'type': detection_type,
                    'confidence': confidence
                })
        
        if confidence_count > 0:
            summary['avg_confidence'] = total_confidence / confidence_count
        
        return summary
    
    def _save_results(self, video_path: str, results: Dict):
        """ä¿å­˜æ£€æµ‹ç»“æœ"""
        video_name = os.path.basename(video_path).split('.')[0]
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = f"video_test_results_{video_name}_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç®€åŒ–æŠ¥å‘Š
        report_file = f"video_test_report_{video_name}_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"è§†é¢‘æ£€æµ‹æŠ¥å‘Š\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"è§†é¢‘æ–‡ä»¶: {video_path}\n")
            f.write(f"å¤„ç†æ—¶é—´: {results['processing_time']:.2f}ç§’\n")
            f.write(f"æ€»å¸§æ•°: {results['video_info']['total_frames']}\n")
            f.write(f"å¤„ç†å¸§æ•°: {results['processing_stats']['processed_frames']}\n")
            f.write(f"æ£€æµ‹æ€»æ•°: {results['processing_stats']['total_detections']}\n")
            f.write(f"å‘Šè­¦æ€»æ•°: {results['processing_stats']['alerts_generated']}\n\n")
            
            summary = results.get('detection_summary', {})
            f.write(f"æ£€æµ‹æ±‡æ€»:\n")
            f.write(f"- è·Œå€’æ£€æµ‹: {summary.get('fall_detections', 0)}\n")
            f.write(f"- ç«ç„°æ£€æµ‹: {summary.get('fire_detections', 0)}\n")
            f.write(f"- çƒŸé›¾æ£€æµ‹: {summary.get('smoke_detections', 0)}\n")
            f.write(f"- å¹³å‡ç½®ä¿¡åº¦: {summary.get('avg_confidence', 0):.3f}\n\n")
            
            if results.get('alerts'):
                f.write(f"å‘Šè­¦åˆ—è¡¨:\n")
                for i, alert in enumerate(results['alerts'], 1):
                    f.write(f"{i}. {alert['severity']}: {alert['message']}\n")
        
        logger.info(f"ç»“æœå·²ä¿å­˜: {results_file}, {report_file}")

class MockUnifiedDetector:
    """æ¨¡æ‹Ÿç»Ÿä¸€æ£€æµ‹å™¨ (å½“çœŸå®æ£€æµ‹å™¨ä¸å¯ç”¨æ—¶)"""
    
    def process_frame(self, frame, camera_id, enable_fall=True, enable_fire=True):
        import random
        
        detections = []
        alerts = []
        
        # æ¨¡æ‹Ÿæ£€æµ‹é€»è¾‘
        if enable_fall and random.random() < 0.1:  # 10%æ¦‚ç‡æ£€æµ‹åˆ°è·Œå€’
            detection = {
                'type': 'fall',
                'confidence': round(random.uniform(0.7, 0.95), 2),
                'person_id': f'person_{random.randint(1, 3)}',
                'timestamp': datetime.now().isoformat()
            }
            detections.append(detection)
            
            if detection['confidence'] > 0.8:
                alerts.append({
                    'id': f"fall_{int(time.time() * 1000)}",
                    'type': 'fall',
                    'severity': 'HIGH',
                    'message': f"æ£€æµ‹åˆ°è·Œå€’ï¼Œç½®ä¿¡åº¦: {detection['confidence']:.2f}",
                    'timestamp': detection['timestamp']
                })
        
        if enable_fire and random.random() < 0.05:  # 5%æ¦‚ç‡æ£€æµ‹åˆ°ç«ç„°
            detection = {
                'type': 'fire',
                'confidence': round(random.uniform(0.6, 0.9), 2),
                'bbox': [100, 100, 200, 200],
                'timestamp': datetime.now().isoformat()
            }
            detections.append(detection)
            
            if detection['confidence'] > 0.7:
                alerts.append({
                    'id': f"fire_{int(time.time() * 1000)}",
                    'type': 'fire',
                    'severity': 'CRITICAL',
                    'message': f"æ£€æµ‹åˆ°ç«ç„°ï¼Œç½®ä¿¡åº¦: {detection['confidence']:.2f}",
                    'timestamp': detection['timestamp']
                })
        
        return {
            'camera_id': camera_id,
            'timestamp': datetime.now().isoformat(),
            'detections': detections,
            'alerts': alerts,
            'processing_time': round(random.uniform(0.1, 0.3), 3)
        }

def create_test_video_info():
    """åˆ›å»ºæµ‹è¯•è§†é¢‘ä¿¡æ¯"""
    return {
        'fall_videos': [
            {
                'name': 'elderly_fall_001.mp4',
                'description': 'è€äººåœ¨å§å®¤è·Œå€’',
                'expected_detections': ['fall'],
                'duration': '30ç§’',
                'resolution': '1280x720'
            },
            {
                'name': 'elderly_fall_002.mp4', 
                'description': 'è€äººåœ¨å®¢å…è·Œå€’',
                'expected_detections': ['fall'],
                'duration': '45ç§’',
                'resolution': '1920x1080'
            }
        ],
        'fire_videos': [
            {
                'name': 'house_fire_001.mp4',
                'description': 'å®¤å†…ç«ç¾åœºæ™¯',
                'expected_detections': ['fire', 'smoke'],
                'duration': '60ç§’',
                'resolution': '1280x720'
            },
            {
                'name': 'smoke_detection_001.mp4',
                'description': 'çƒŸé›¾æ£€æµ‹åœºæ™¯',
                'expected_detections': ['smoke'],
                'duration': '40ç§’',
                'resolution': '1920x1080'
            }
        ]
    }

if __name__ == "__main__":
    # æµ‹è¯•è§†é¢‘å¤„ç†å™¨
    processor = VideoProcessor()
    
    # æ˜¾ç¤ºæµ‹è¯•è§†é¢‘ä¿¡æ¯
    test_videos = create_test_video_info()
    print("ğŸ“¹ æ”¯æŒçš„æµ‹è¯•è§†é¢‘ç±»å‹:")
    print("\nè·Œå€’æ£€æµ‹è§†é¢‘:")
    for video in test_videos['fall_videos']:
        print(f"  - {video['name']}: {video['description']}")
    
    print("\nç«ç„°/çƒŸé›¾æ£€æµ‹è§†é¢‘:")
    for video in test_videos['fire_videos']:
        print(f"  - {video['name']}: {video['description']}")
    
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("processor.process_video_file('path/to/video.mp4', 'camera_01')")
    print("processor.process_video_realtime('path/to/video.mp4', 'live_01')")