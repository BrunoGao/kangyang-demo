import cv2
import numpy as np
import mediapipe as mp
import time
import os
from typing import Dict, List, Tuple, Optional
import json
import redis
from datetime import datetime

class FallDetector:
    def __init__(self):
        # åˆå§‹åŒ–MediaPipeå§¿æ€æ£€æµ‹
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        # è·Œå€’æ£€æµ‹å‚æ•°
        self.fall_threshold = 0.7  # è·Œå€’é˜ˆå€¼
        self.lying_time_threshold = 5.0  # èººå€’æ—¶é—´é˜ˆå€¼(ç§’)
        self.person_states = {}  # å­˜å‚¨æ¯ä¸ªäººçš„çŠ¶æ€
        
        # Redisè¿æ¥
        try:
            redis_host = os.getenv('REDIS_HOST', 'localhost')
            redis_port = int(os.getenv('REDIS_PORT', '6379'))
            self.redis_client = redis.Redis(host=redis_host, port=redis_port, db=0, decode_responses=True)
        except:
            self.redis_client = None
            print("Redisè¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°å­˜å‚¨")

    def calculate_body_angle(self, landmarks) -> float:
        """è®¡ç®—äººä½“å€¾æ–œè§’åº¦"""
        try:
            # è·å–å…³é”®ç‚¹
            left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value]
            right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value]
            left_hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value]
            right_hip = landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value]
            
            # è®¡ç®—è‚©è†€å’Œè‡€éƒ¨ä¸­ç‚¹
            shoulder_center = [(left_shoulder.x + right_shoulder.x) / 2, 
                             (left_shoulder.y + right_shoulder.y) / 2]
            hip_center = [(left_hip.x + right_hip.x) / 2, 
                         (left_hip.y + right_hip.y) / 2]
            
            # è®¡ç®—èº¯å¹²ä¸å‚ç›´æ–¹å‘çš„è§’åº¦
            dx = hip_center[0] - shoulder_center[0]
            dy = hip_center[1] - shoulder_center[1]
            
            angle = abs(np.arctan2(dx, dy))
            return angle
        except:
            return 0.0

    def detect_fall(self, landmarks, person_id: str = "person_1") -> Dict:
        """æ£€æµ‹è·Œå€’"""
        current_time = time.time()
        
        # è®¡ç®—èº«ä½“è§’åº¦
        body_angle = self.calculate_body_angle(landmarks)
        
        # åˆ¤æ–­æ˜¯å¦è·Œå€’
        is_fallen = body_angle > self.fall_threshold
        
        # è·å–æˆ–åˆå§‹åŒ–äººå‘˜çŠ¶æ€
        if person_id not in self.person_states:
            self.person_states[person_id] = {
                'is_fallen': False,
                'fall_start_time': None,
                'last_alert_time': 0,
                'consecutive_fall_frames': 0
            }
        
        state = self.person_states[person_id]
        
        if is_fallen:
            state['consecutive_fall_frames'] += 1
            if not state['is_fallen'] and state['consecutive_fall_frames'] > 5:  # è¿ç»­5å¸§ç¡®è®¤è·Œå€’
                state['is_fallen'] = True
                state['fall_start_time'] = current_time
                # å‘é€å³æ—¶è·Œå€’å‘Šè­¦
                self.send_alert({
                    'type': 'fall_detected',
                    'person_id': person_id,
                    'timestamp': datetime.now().isoformat(),
                    'body_angle': round(body_angle, 2),
                    'severity': 'immediate'
                })
        else:
            state['consecutive_fall_frames'] = 0
            if state['is_fallen']:
                state['is_fallen'] = False
                state['fall_start_time'] = None
        
        # æ£€æŸ¥é•¿æ—¶é—´èººå€’
        if state['is_fallen'] and state['fall_start_time']:
            lying_duration = current_time - state['fall_start_time']
            if lying_duration > self.lying_time_threshold:
                # æ¯30ç§’å‘é€ä¸€æ¬¡æŒç»­å‘Šè­¦
                if current_time - state['last_alert_time'] > 30:
                    state['last_alert_time'] = current_time
                    self.send_alert({
                        'type': 'prolonged_fall',
                        'person_id': person_id,
                        'timestamp': datetime.now().isoformat(),
                        'duration': round(lying_duration, 1),
                        'severity': 'critical'
                    })
        
        return {
            'is_fallen': state['is_fallen'],
            'body_angle': round(body_angle, 2),
            'lying_duration': round(current_time - state['fall_start_time'], 1) if state['fall_start_time'] else 0,
            'person_id': person_id
        }

    def send_alert(self, alert_data: Dict):
        """å‘é€å‘Šè­¦ä¿¡æ¯"""
        try:
            if self.redis_client:
                # å‘å¸ƒåˆ°Redisé¢‘é“
                self.redis_client.publish('fall_alerts', json.dumps(alert_data))
                # å­˜å‚¨åˆ°Redisåˆ—è¡¨
                self.redis_client.lpush('fall_events', json.dumps(alert_data))
                self.redis_client.ltrim('fall_events', 0, 999)  # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            
            print(f"ğŸš¨ è·Œå€’å‘Šè­¦: {alert_data}")
        except Exception as e:
            print(f"å‘é€å‘Šè­¦å¤±è´¥: {e}")

    def process_frame(self, frame: np.ndarray, camera_id: str = "camera_1") -> Tuple[np.ndarray, List[Dict]]:
        """å¤„ç†å•å¸§å›¾åƒ"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(rgb_frame)
        
        detections = []
        
        if results.pose_landmarks:
            # ç»˜åˆ¶å§¿æ€å…³é”®ç‚¹
            self.mp_drawing.draw_landmarks(
                frame, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)
            
            # æ£€æµ‹è·Œå€’
            detection_result = self.detect_fall(results.pose_landmarks.landmark)
            detections.append(detection_result)
            
            # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºæ£€æµ‹ç»“æœ
            status_text = "ğŸš¨ è·Œå€’" if detection_result['is_fallen'] else "âœ… æ­£å¸¸"
            color = (0, 0, 255) if detection_result['is_fallen'] else (0, 255, 0)
            
            cv2.putText(frame, status_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            cv2.putText(frame, f"è§’åº¦: {detection_result['body_angle']}", 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            if detection_result['lying_duration'] > 0:
                cv2.putText(frame, f"æŒç»­: {detection_result['lying_duration']}s", 
                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        return frame, detections

    def process_video_stream(self, source=0):
        """å¤„ç†è§†é¢‘æµ"""
        cap = cv2.VideoCapture(source)
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            processed_frame, detections = self.process_frame(frame)
            
            cv2.imshow('Fall Detection Demo', processed_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    detector = FallDetector()
    print("å¯åŠ¨è·Œå€’æ£€æµ‹æ¼”ç¤º...")
    print("æŒ‰ 'q' é€€å‡º")
    detector.process_video_stream(0)  # ä½¿ç”¨æ‘„åƒå¤´0