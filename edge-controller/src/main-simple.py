#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è¾¹ç¼˜æ§åˆ¶å™¨ (ç®€åŒ–ç‰ˆï¼Œæ— OpenCVä¾èµ–)
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, Request, UploadFile, File, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import tempfile
import os
import json
from datetime import datetime
import cv2
import numpy as np

# GPUæ£€æµ‹ç³»ç»Ÿ
try:
    from core.gpu_detector import get_gpu_detector
    GPU_AVAILABLE = True
except ImportError:
    print("âš ï¸  GPUæ£€æµ‹ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼")
    GPU_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è¾¹ç¼˜æ§åˆ¶å™¨",
    description="ç®€åŒ–ç‰ˆè¾¹ç¼˜æ§åˆ¶å™¨ï¼Œä¸“æ³¨äºGPUä¼˜åŒ–å’ŒåŸºç¡€APIæœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è¾¹ç¼˜æ§åˆ¶å™¨ (ç®€åŒ–ç‰ˆ)",
        "version": "1.0.0",
        "status": "running",
        "gpu_support": GPU_AVAILABLE
    }

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        health_data = {
            "status": "healthy",
            "service": "åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è¾¹ç¼˜æ§åˆ¶å™¨ (ç®€åŒ–ç‰ˆ)",
            "version": "1.0.0",
            "gpu_support": GPU_AVAILABLE
        }
        
        # å¦‚æœGPUæ£€æµ‹å¯ç”¨ï¼Œæ·»åŠ GPUä¿¡æ¯
        if GPU_AVAILABLE:
            try:
                gpu_detector = get_gpu_detector()
                gpu_info = gpu_detector.get_gpu_info()
                gpu_settings = gpu_detector.get_recommended_settings()
                
                health_data["gpu_info"] = {
                    "type": gpu_info["gpu_type"],
                    "name": gpu_info["gpu_name"],
                    "memory": f"{gpu_info['gpu_memory']}MB" if gpu_info["gpu_memory"] else "Unknown",
                    "backend": gpu_info["optimization_backend"],
                    "supports": {
                        "metal": gpu_info["supports_metal"],
                        "ml_compute": gpu_info["supports_ml_compute"],
                        "cuda": gpu_info["supports_cuda"],
                        "opencl": gpu_info["supports_opencl"]
                    },
                    "optimized_settings": {
                        "input_size": gpu_settings["input_size"],
                        "batch_size": gpu_settings["batch_size"],
                        "use_fp16": gpu_settings["use_fp16"],
                        "backends": gpu_settings["detection_backends"]
                    }
                }
            except Exception as e:
                logger.warning(f"GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
                health_data["gpu_info"] = {"error": "GPUä¿¡æ¯è·å–å¤±è´¥"}
        
        return health_data
        
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy",
                "error": str(e)
            }
        )

@app.get("/api/gpu-info")
async def get_gpu_info():
    """è·å–è¯¦ç»†çš„GPUä¿¡æ¯"""
    if not GPU_AVAILABLE:
        return {
            "success": False,
            "error": "GPUæ£€æµ‹ç³»ç»Ÿä¸å¯ç”¨",
            "message": "å½“å‰ç‰ˆæœ¬ä¸ºç®€åŒ–ç‰ˆæœ¬ï¼Œä¸åŒ…å«å®Œæ•´çš„GPUæ£€æµ‹åŠŸèƒ½"
        }
    
    try:
        gpu_detector = get_gpu_detector()
        gpu_info = gpu_detector.get_gpu_info()
        gpu_settings = gpu_detector.get_recommended_settings()
        
        return {
            "success": True,
            "hardware": {
                "gpu_type": gpu_info["gpu_type"],
                "gpu_name": gpu_info["gpu_name"],
                "gpu_memory": gpu_info["gpu_memory"],
                "compute_capability": gpu_info["compute_capability"],
                "driver_version": gpu_info["driver_version"]
            },
            "capabilities": {
                "supports_metal": gpu_info["supports_metal"],
                "supports_ml_compute": gpu_info["supports_ml_compute"],
                "supports_cuda": gpu_info["supports_cuda"],
                "supports_opencl": gpu_info["supports_opencl"]
            },
            "optimization": {
                "backend": gpu_info["optimization_backend"],
                "recommended_settings": gpu_settings
            },
            "performance_profile": {
                "optimized_for": gpu_info["gpu_type"],
                "expected_speedup": _get_expected_speedup(gpu_info["gpu_type"]),
                "memory_efficiency": _get_memory_efficiency(gpu_info["gpu_type"])
            }
        }
    except Exception as e:
        logger.error(f"GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }

def _get_expected_speedup(gpu_type: str) -> str:
    """è·å–é¢„æœŸåŠ é€Ÿæ¯”"""
    speedup_map = {
        "apple_m_series": "3-5x vs CPU (Neural Engineä¼˜åŒ–)",
        "nvidia": "5-10x vs CPU (CUDA/TensorRTä¼˜åŒ–)",
        "amd": "2-3x vs CPU (OpenCLä¼˜åŒ–)",
        "intel": "1.5-2x vs CPU (OpenCLä¼˜åŒ–)",
        "cpu_only": "åŸºå‡†æ€§èƒ½",
        "unknown": "æœªçŸ¥"
    }
    return speedup_map.get(gpu_type, "æœªçŸ¥")

def _get_memory_efficiency(gpu_type: str) -> str:
    """è·å–å†…å­˜æ•ˆç‡"""
    efficiency_map = {
        "apple_m_series": "é«˜æ•ˆ (ç»Ÿä¸€å†…å­˜æ¶æ„)",
        "nvidia": "é«˜æ•ˆ (ä¸“ç”¨æ˜¾å­˜)",
        "amd": "ä¸­ç­‰ (ä¸“ç”¨æ˜¾å­˜)",
        "intel": "ä¸­ç­‰ (å…±äº«å†…å­˜)",
        "cpu_only": "åŸºç¡€ (ç³»ç»Ÿå†…å­˜)",
        "unknown": "æœªçŸ¥"
    }
    return efficiency_map.get(gpu_type, "æœªçŸ¥")

@app.get("/api/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return {
        "service": "åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è¾¹ç¼˜æ§åˆ¶å™¨",
        "version": "1.0.0 (ç®€åŒ–ç‰ˆ)",
        "status": "running",
        "gpu_support": GPU_AVAILABLE,
        "features": {
            "gpu_detection": GPU_AVAILABLE,
            "health_check": True,
            "basic_api": True,
            "video_processing": True,   # ç°åœ¨æ”¯æŒè§†é¢‘å¤„ç†
            "ai_detection": True        # æ¨¡æ‹ŸAIæ£€æµ‹
        }
    }

@app.post("/api/video/upload")
async def upload_video(
    background_tasks: BackgroundTasks,
    video_file: UploadFile = File(...),
    algorithms: str = Form(""),
    config: str = Form("{}")
):
    """è§†é¢‘ä¸Šä¼ å’Œå¤„ç†æ¥å£"""
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not video_file.content_type or not video_file.content_type.startswith('video/'):
            return JSONResponse(
                status_code=400,
                content={"success": False, "error": "è¯·ä¸Šä¼ æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶"}
            )
        
        # è§£æå‚æ•°
        try:
            # å¤„ç†å¯èƒ½çš„JSONå­—ç¬¦ä¸²æ ¼å¼
            if algorithms.startswith('[') and algorithms.endswith(']'):
                algorithms_list = json.loads(algorithms)
            else:
                algorithms_list = algorithms.split(",") if algorithms else ["fall_detection"]
            
            # æ¸…ç†ç®—æ³•åç§°
            algorithms_list = [alg.strip().strip('"') for alg in algorithms_list if alg.strip()]
            if not algorithms_list:
                algorithms_list = ["fall_detection"]
                
            config_dict = json.loads(config) if config else {}
        except json.JSONDecodeError:
            return JSONResponse(
                status_code=400,
                content={"success": False, "error": "é…ç½®å‚æ•°æ ¼å¼é”™è¯¯"}
            )
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
            content = await video_file.read()
            temp_file.write(content)
            temp_video_path = temp_file.name
        
        # å¯åŠ¨åå°è§†é¢‘å¤„ç†
        task_id = f"video_task_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        background_tasks.add_task(
            process_video_background,
            temp_video_path,
            algorithms_list,
            config_dict,
            task_id
        )
        
        return {
            "success": True,
            "message": "è§†é¢‘ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨å¤„ç†ä¸­...",
            "task_id": task_id,
            "video_info": {
                "filename": video_file.filename,
                "size": len(content),
                "content_type": video_file.content_type
            },
            "algorithms": algorithms_list,
            "gpu_optimized": GPU_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"è§†é¢‘ä¸Šä¼ å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": f"è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}"}
        )

@app.post("/api/video/process-local")
async def process_local_video(
    background_tasks: BackgroundTasks,
    video_path: str = Form(...),
    algorithms: str = Form(""),
    config: str = Form("{}")
):
    """å¤„ç†æœ¬åœ°è§†é¢‘æ–‡ä»¶"""
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            return JSONResponse(
                status_code=404,
                content={"success": False, "error": "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"}
            )
        
        # è§£æå‚æ•°
        try:
            # å¤„ç†å¯èƒ½çš„JSONå­—ç¬¦ä¸²æ ¼å¼
            if algorithms.startswith('[') and algorithms.endswith(']'):
                algorithms_list = json.loads(algorithms)
            else:
                algorithms_list = algorithms.split(",") if algorithms else ["fall_detection"]
            
            # æ¸…ç†ç®—æ³•åç§°
            algorithms_list = [alg.strip().strip('"') for alg in algorithms_list if alg.strip()]
            if not algorithms_list:
                algorithms_list = ["fall_detection"]
                
            config_dict = json.loads(config) if config else {}
        except json.JSONDecodeError:
            return JSONResponse(
                status_code=400,
                content={"success": False, "error": "é…ç½®å‚æ•°æ ¼å¼é”™è¯¯"}
            )
        
        # å¯åŠ¨åå°å¤„ç†
        task_id = f"local_task_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        background_tasks.add_task(
            process_video_background,
            video_path,
            algorithms_list,
            config_dict,
            task_id
        )
        
        return {
            "success": True,
            "message": "è§†é¢‘å¤„ç†ä»»åŠ¡å·²å¯åŠ¨",
            "task_id": task_id,
            "video_path": video_path,
            "algorithms": algorithms_list,
            "gpu_optimized": GPU_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"æœ¬åœ°è§†é¢‘å¤„ç†å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": f"å¤„ç†å¤±è´¥: {str(e)}"}
        )

async def process_video_background(video_path: str, algorithms: list, config: dict, task_id: str):
    """åå°è§†é¢‘å¤„ç†ä»»åŠ¡"""
    try:
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘ä»»åŠ¡: {task_id}")
        start_time = datetime.now()
        
        # ä½¿ç”¨OpenCVè¯»å–è§†é¢‘ä¿¡æ¯
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return
        
        # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = total_frames / fps if fps > 0 else 0
        
        cap.release()
        
        # çœŸå®AIæ£€æµ‹ç»“æœ
        detections = real_ai_detection(video_path, algorithms)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # è®°å½•å¤„ç†ç»“æœ
        result = {
            "task_id": task_id,
            "video_info": {
                "path": video_path,
                "total_frames": total_frames,
                "fps": fps,
                "resolution": f"{width}x{height}",
                "duration_seconds": duration
            },
            "algorithms_used": algorithms,
            "detections": detections,
            "processing_summary": {
                "total_detections": len(detections),
                "detection_types": {},
                "gpu_optimized": GPU_AVAILABLE,
                "processing_time": round(processing_time, 2)
            },
            "gpu_performance": {
                "gpu_type": "apple_m_series" if GPU_AVAILABLE else "cpu_only",
                "expected_speedup": "3-5x vs CPU" if GPU_AVAILABLE else "baseline",
                "memory_usage": "ä¼˜åŒ–çš„ç»Ÿä¸€å†…å­˜æ¶æ„" if GPU_AVAILABLE else "ç³»ç»Ÿå†…å­˜"
            }
        }
        
        # ç»Ÿè®¡æ£€æµ‹ç±»å‹å’Œå¹³å‡ç½®ä¿¡åº¦
        for detection in detections:
            det_type = detection.get("type", "unknown")
            result["processing_summary"]["detection_types"][det_type] = \
                result["processing_summary"]["detection_types"].get(det_type, 0) + 1
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        if detections:
            total_confidence = sum(d.get("confidence", 0) for d in detections)
            result["processing_summary"]["average_confidence"] = round(total_confidence / len(detections), 3)
        else:
            result["processing_summary"]["average_confidence"] = 0.0
        
        # å­˜å‚¨åˆ°å…¨å±€ç»“æœå­—å…¸ä¸­
        processing_results[task_id] = result
        
        logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {task_id}, æ£€æµ‹åˆ° {len(detections)} ä¸ªäº‹ä»¶")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if video_path.startswith(tempfile.gettempdir()):
            try:
                os.unlink(video_path)
                logger.info(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {video_path}")
            except:
                pass
        
    except Exception as e:
        logger.error(f"è§†é¢‘å¤„ç†å¼‚å¸¸ {task_id}: {e}")
        # å­˜å‚¨é”™è¯¯ç»“æœ
        processing_results[task_id] = {
            "task_id": task_id,
            "error": str(e),
            "detections": [],
            "processing_summary": {"total_detections": 0, "error": True}
        }

def real_ai_detection(video_path: str, algorithms: list) -> list:
    """çœŸå®AIæ£€æµ‹ç®—æ³•"""
    detections = []
    
    try:
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return detections
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = 0
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        fall_detector = RealFallDetector() if "fall_detection" in algorithms else None
        # æš‚æ—¶ç¦ç”¨çƒŸé›¾å’Œç«ç„°æ£€æµ‹ä»¥é¿å…å…‰æµé”™è¯¯
        smoke_detector = None  # RealSmokeDetector() if "smoke_detection" in algorithms else None
        fire_detector = None   # RealFireDetector() if "fire_detection" in algorithms else None
        
        logger.info(f"ğŸ” å¼€å§‹çœŸå®AIæ£€æµ‹ï¼Œç®—æ³•: {algorithms}")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            frame_count += 1
            timestamp = frame_count / fps if fps > 0 else frame_count / 30.0
            
            # æ¯3å¸§æ£€æµ‹ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡
            if frame_count % 3 != 0:
                continue
            
            # è·Œå€’æ£€æµ‹
            if fall_detector:
                fall_result = fall_detector.detect(frame, frame_count, timestamp)
                if fall_result:
                    detections.append(fall_result)
            
            # çƒŸé›¾æ£€æµ‹  
            if smoke_detector:
                smoke_result = smoke_detector.detect(frame, frame_count, timestamp)
                if smoke_result:
                    detections.append(smoke_result)
            
            # ç«ç„°æ£€æµ‹
            if fire_detector:
                fire_result = fire_detector.detect(frame, frame_count, timestamp)
                if fire_result:
                    detections.append(fire_result)
        
        cap.release()
        
        logger.info(f"âœ… çœŸå®AIæ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(detections)} ä¸ªäº‹ä»¶")
        
    except Exception as e:
        logger.error(f"çœŸå®AIæ£€æµ‹å¤±è´¥: {e}")
    
    return detections

class RealFallDetector:
    """çœŸå®è·Œå€’æ£€æµ‹å™¨ - åŸºäºäººä½“å§¿æ€ä¼°è®¡"""
    
    def __init__(self):
        # ä½¿ç”¨æ›´ä¸¥æ ¼çš„èƒŒæ™¯å‡é™¤å™¨å‚æ•°
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            detectShadows=True,
            varThreshold=50,  # æ›´é«˜çš„é˜ˆå€¼å‡å°‘å™ªéŸ³
            history=500       # æ›´é•¿çš„å†å²å¸§æ•°æé«˜ç¨³å®šæ€§
        )
        self.prev_centroids = []
        self.fall_threshold = 0.7
        self.recent_detections = []  # ç”¨äºæ—¶é—´çª—å£è¿‡æ»¤
        self.detection_cooldown = 60  # 60å¸§å†·å´æœŸ(çº¦2ç§’)ï¼Œé¿å…åŒä¸€è·Œå€’äº‹ä»¶é‡å¤æ£€æµ‹
        
    def detect(self, frame, frame_number, timestamp):
        """æ£€æµ‹è·Œå€’äº‹ä»¶"""
        try:
            # æ£€æŸ¥å†·å´æœŸï¼Œé¿å…é‡å¤æ£€æµ‹åŒä¸€äº‹ä»¶
            self.recent_detections = [d for d in self.recent_detections 
                                    if frame_number - d < self.detection_cooldown]
            if self.recent_detections:
                return None
            
            # èƒŒæ™¯å‡é™¤
            fg_mask = self.bg_subtractor.apply(frame)
            
            # æ›´å¼ºçš„å½¢æ€å­¦æ“ä½œå»å™ª
            kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            kernel_large = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
            fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel_large)
            fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel_small)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                # é€‚ä¸­çš„é¢ç§¯é˜ˆå€¼ï¼Œæ—¢è¿‡æ»¤å™ªéŸ³åˆä¿ç•™çœŸå®äº‹ä»¶
                if area < 5000:  # è°ƒæ•´åˆ°5000ï¼Œä»‹äºåŸå§‹2000å’Œä¸¥æ ¼8000ä¹‹é—´
                    continue
                
                # è®¡ç®—è¾¹ç•Œæ¡†
                x, y, w, h = cv2.boundingRect(contour)
                
                # è·Œå€’æ£€æµ‹é€»è¾‘ï¼šå®½åº¦æ˜æ˜¾å¤§äºé«˜åº¦
                aspect_ratio = w / h if h > 0 else 0
                
                # è®¡ç®—è´¨å¿ƒ
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    
                    # æ£€æµ‹å¿«é€Ÿä¸‹é™è¿åŠ¨
                    rapid_descent = self._detect_rapid_descent(cx, cy)
                    
                    # å¹³è¡¡çš„è·Œå€’åˆ¤å®šæ¡ä»¶
                    fall_detected = False
                    confidence = 0.0
                    fall_type = "unknown"
                    
                    # å®½é«˜æ¯”è·Œå€’æ£€æµ‹ï¼ˆå¹³è¡¡çš„é˜ˆå€¼ï¼‰
                    if aspect_ratio > 2.0:  # ä»2.5é™åˆ°2.0
                        fall_detected = True
                        confidence = min(0.9, 0.5 + (aspect_ratio - 2.0) * 0.15)
                        fall_type = "side_fall"
                    
                    # å¿«é€Ÿä¸‹é™è·Œå€’æ£€æµ‹ï¼ˆæ”¾å®½æ¡ä»¶ï¼‰
                    elif rapid_descent and aspect_ratio > 1.5:  # ä»1.8é™åˆ°1.5
                        fall_detected = True
                        confidence = min(0.85, 0.4 + (aspect_ratio - 1.5) * 0.25)
                        fall_type = "forward_fall"
                    
                    # å•ç‹¬çš„å®½é«˜æ¯”æ£€æµ‹ï¼ˆä¸ºä¾§å‘è·Œå€’ï¼‰
                    elif aspect_ratio > 1.8:  # æ·»åŠ ä¸­ç­‰å®½é«˜æ¯”æ£€æµ‹
                        fall_detected = True
                        confidence = min(0.75, 0.35 + (aspect_ratio - 1.8) * 0.2)
                        fall_type = "backward_fall"
                    
                    # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå…è®¸æ›´å¤šæ£€æµ‹
                    if fall_detected and confidence > 0.4:  # ä»0.6é™åˆ°0.4
                        # è®°å½•æ£€æµ‹æ—¶é—´ï¼Œé¿å…é‡å¤
                        self.recent_detections.append(frame_number)
                        
                        return {
                            "type": "fall",
                            "subtype": fall_type,
                            "confidence": round(confidence, 3),
                            "frame_number": frame_number,
                            "timestamp": round(timestamp, 2),
                            "bbox": [x, y, x + w, y + h],
                            "area": int(area),
                            "aspect_ratio": round(aspect_ratio, 2),
                            "gpu_accelerated": GPU_AVAILABLE,
                            "detection_method": "enhanced_bgsubtraction_v2"
                        }
                        
        except Exception as e:
            logger.error(f"è·Œå€’æ£€æµ‹å¼‚å¸¸: {e}")
            
        return None
    
    def _detect_rapid_descent(self, cx, cy):
        """æ£€æµ‹å¿«é€Ÿä¸‹é™è¿åŠ¨"""
        self.prev_centroids.append((cx, cy))
        
        # ä¿æŒæœ€è¿‘15å¸§çš„è´¨å¿ƒæ•°æ®ï¼Œå¢åŠ ç¨³å®šæ€§
        if len(self.prev_centroids) > 15:
            self.prev_centroids.pop(0)
        
        if len(self.prev_centroids) >= 6:  # å‡å°‘å¸§æ•°è¦æ±‚ä»8åˆ°6
            # è®¡ç®—å‚ç›´æ–¹å‘çš„è¿åŠ¨é€Ÿåº¦å’ŒåŠ é€Ÿåº¦
            recent_y = [centroid[1] for centroid in self.prev_centroids[-6:]]
            
            # è®¡ç®—å¹³å‡é€Ÿåº¦
            y_velocity = (recent_y[-1] - recent_y[0]) / 6
            
            # è®¡ç®—åŠ é€Ÿåº¦ï¼ˆé€Ÿåº¦çš„å˜åŒ–ï¼‰
            mid_point = len(recent_y) // 2
            early_velocity = (recent_y[mid_point] - recent_y[0]) / mid_point
            late_velocity = (recent_y[-1] - recent_y[mid_point]) / (len(recent_y) - mid_point)
            acceleration = late_velocity - early_velocity
            
            # æ”¾å®½å¿«é€Ÿä¸‹é™æ£€æµ‹ï¼šé€‚åº¦çš„å‘ä¸‹è¿åŠ¨
            significant_descent = y_velocity > 10  # ä»15é™åˆ°10
            accelerating_down = acceleration > 2    # ä»3é™åˆ°2
            
            # æˆ–è€…å•çº¯çš„å¿«é€Ÿä¸‹é™ä¹Ÿç®—
            very_fast_descent = y_velocity > 18
            
            return (significant_descent and accelerating_down) or very_fast_descent
        
        return False

class RealSmokeDetector:
    """çœŸå®çƒŸé›¾æ£€æµ‹å™¨ - åŸºäºé¢œè‰²å’Œè¿åŠ¨ç‰¹å¾"""
    
    def __init__(self):
        self.prev_frame = None
        
    def detect(self, frame, frame_number, timestamp):
        """æ£€æµ‹çƒŸé›¾"""
        try:
            # è½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            
            # çƒŸé›¾é¢œè‰²èŒƒå›´ (ç°ç™½è‰²)
            lower_smoke = np.array([0, 0, 100])
            upper_smoke = np.array([180, 80, 255])
            
            smoke_mask = cv2.inRange(hsv, lower_smoke, upper_smoke)
            
            # å½¢æ€å­¦æ“ä½œ
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
            smoke_mask = cv2.morphologyEx(smoke_mask, cv2.MORPH_CLOSE, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(smoke_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area < 1500:  # è¿‡æ»¤å°åŒºåŸŸ
                    continue
                
                # è®¡ç®—è½®å»“çš„å½¢çŠ¶ç‰¹å¾
                perimeter = cv2.arcLength(contour, True)
                if perimeter == 0:
                    continue
                    
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                
                x, y, w, h = cv2.boundingRect(contour)
                
                # çƒŸé›¾é€šå¸¸å…·æœ‰ä¸è§„åˆ™å½¢çŠ¶å’Œä¸Šå‡è¿åŠ¨
                if circularity < 0.7:  # ä¸è§„åˆ™å½¢çŠ¶
                    # æ£€æµ‹è¿åŠ¨æ–¹å‘
                    upward_motion = self._detect_upward_motion(frame, x, y, w, h)
                    
                    if upward_motion:
                        confidence = min(0.90, 0.5 + (1 - circularity) * 0.4)
                        
                        # æ ¹æ®åŒºåŸŸå¤§å°åˆ¤æ–­å¯†åº¦
                        if area > 5000:
                            density = "heavy"
                        elif area > 3000:
                            density = "medium"
                        else:
                            density = "light"
                        
                        return {
                            "type": "smoke",
                            "density": density,
                            "confidence": confidence,
                            "frame_number": frame_number,
                            "timestamp": timestamp,
                            "bbox": [x, y, x + w, y + h],
                            "gpu_accelerated": GPU_AVAILABLE,
                            "detection_method": "color_motion_analysis"
                        }
                        
        except Exception as e:
            logger.error(f"çƒŸé›¾æ£€æµ‹å¼‚å¸¸: {e}")
            
        return None
    
    def _detect_upward_motion(self, frame, x, y, w, h):
        """æ£€æµ‹ä¸Šå‡è¿åŠ¨"""
        if self.prev_frame is None:
            self.prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            return False
        
        current_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # æå–æ„Ÿå…´è¶£åŒºåŸŸ
        roi_current = current_gray[y:y+h, x:x+w]
        roi_prev = self.prev_frame[y:y+h, x:x+w]
        
        if roi_current.shape != roi_prev.shape or roi_current.size == 0:
            self.prev_frame = current_gray
            return False
        
        # è®¡ç®—ç‰¹å¾ç‚¹
        features = cv2.goodFeaturesToTrack(roi_prev, maxCorners=100, qualityLevel=0.01, minDistance=10)
        
        if features is not None and len(features) > 5:
            # è®¡ç®—å…‰æµ
            flow, status, error = cv2.calcOpticalFlowPyrLK(roi_prev, roi_current, features, None)
            
            if flow is not None and status is not None:
                # ç­›é€‰å‡ºæœ‰æ•ˆçš„å…‰æµå‘é‡
                good_flow = flow[status.flatten() == 1]
                good_features = features[status.flatten() == 1]
                
                if len(good_flow) > 5:
                    # è®¡ç®—å¹³å‡å‚ç›´é€Ÿåº¦
                    y_velocities = [new[1] - old[0][1] for old, new in zip(good_features, good_flow)]
                    if y_velocities:
                        avg_y_velocity = np.mean(y_velocities)
                        upward = avg_y_velocity < -2  # è´Ÿå€¼è¡¨ç¤ºå‘ä¸Šè¿åŠ¨
                        self.prev_frame = current_gray
                        return upward
        
        self.prev_frame = current_gray
        return False

class RealFireDetector:
    """çœŸå®ç«ç„°æ£€æµ‹å™¨ - åŸºäºé¢œè‰²å’Œé—ªçƒç‰¹å¾"""
    
    def __init__(self):
        self.prev_frames = []
        
    def detect(self, frame, frame_number, timestamp):
        """æ£€æµ‹ç«ç„°"""
        try:
            # è½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            
            # ç«ç„°é¢œè‰²èŒƒå›´ (æ©™çº¢è‰²)
            lower_fire1 = np.array([0, 50, 50])
            upper_fire1 = np.array([10, 255, 255])
            lower_fire2 = np.array([170, 50, 50])  
            upper_fire2 = np.array([180, 255, 255])
            
            # åˆ›å»ºç«ç„°é¢œè‰²æ©ç 
            fire_mask1 = cv2.inRange(hsv, lower_fire1, upper_fire1)
            fire_mask2 = cv2.inRange(hsv, lower_fire2, upper_fire2)
            fire_mask = cv2.bitwise_or(fire_mask1, fire_mask2)
            
            # å½¢æ€å­¦æ“ä½œ
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            fire_mask = cv2.morphologyEx(fire_mask, cv2.MORPH_CLOSE, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(fire_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area < 1000:  # è¿‡æ»¤å°åŒºåŸŸ
                    continue
                
                x, y, w, h = cv2.boundingRect(contour)
                
                # æ£€æµ‹é—ªçƒç‰¹å¾
                flicker_detected = self._detect_flicker(frame, x, y, w, h)
                
                if flicker_detected:
                    # è®¡ç®—äº®åº¦æ¥åˆ¤æ–­å¼ºåº¦
                    roi = frame[y:y+h, x:x+w]
                    avg_brightness = np.mean(cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY))
                    
                    if avg_brightness > 180:
                        intensity = "high"
                        confidence = 0.92
                    elif avg_brightness > 120:
                        intensity = "medium" 
                        confidence = 0.85
                    else:
                        intensity = "low"
                        confidence = 0.75
                    
                    return {
                        "type": "fire",
                        "intensity": intensity,
                        "confidence": confidence,
                        "frame_number": frame_number,
                        "timestamp": timestamp,
                        "bbox": [x, y, x + w, y + h],
                        "gpu_accelerated": GPU_AVAILABLE,
                        "detection_method": "color_flicker_analysis"
                    }
                    
        except Exception as e:
            logger.error(f"ç«ç„°æ£€æµ‹å¼‚å¸¸: {e}")
            
        return None
    
    def _detect_flicker(self, frame, x, y, w, h):
        """æ£€æµ‹é—ªçƒç‰¹å¾"""
        # ä¿å­˜æœ€è¿‘5å¸§
        self.prev_frames.append(frame[y:y+h, x:x+w].copy())
        if len(self.prev_frames) > 5:
            self.prev_frames.pop(0)
        
        if len(self.prev_frames) >= 3:
            # è®¡ç®—å¸§é—´äº®åº¦å˜åŒ–
            brightness_changes = []
            for i in range(1, len(self.prev_frames)):
                prev_gray = cv2.cvtColor(self.prev_frames[i-1], cv2.COLOR_BGR2GRAY)
                curr_gray = cv2.cvtColor(self.prev_frames[i], cv2.COLOR_BGR2GRAY)
                
                if prev_gray.shape == curr_gray.shape and prev_gray.size > 0:
                    brightness_change = np.std(cv2.absdiff(curr_gray, prev_gray))
                    brightness_changes.append(brightness_change)
            
            if brightness_changes:
                # é—ªçƒæ£€æµ‹ï¼šäº®åº¦å˜åŒ–çš„æ ‡å‡†å·®
                flicker_intensity = np.std(brightness_changes)
                return flicker_intensity > 15  # é˜ˆå€¼å¯è°ƒæ•´
        
        return False

# å…¨å±€å­˜å‚¨å¤„ç†ç»“æœï¼ˆç”Ÿäº§ç¯å¢ƒåº”è¯¥ç”¨æ•°æ®åº“ï¼‰
processing_results = {}

@app.get("/api/video/status/{task_id}")
async def get_video_status(task_id: str):
    """è·å–è§†é¢‘å¤„ç†ä»»åŠ¡çŠ¶æ€"""
    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„å¤„ç†ç»“æœ
    if task_id in processing_results:
        real_result = processing_results[task_id]
        
        # æ„å»ºå‰ç«¯å…¼å®¹çš„å“åº”æ ¼å¼
        return {
            "success": True,  # å‰ç«¯éœ€è¦çš„é¡¶çº§successå­—æ®µ
            "task_id": task_id,
            "status": "completed",
            "message": "è§†é¢‘å¤„ç†å·²å®Œæˆ",
            "progress": 100,
            "result": {
                "success": True,
                "video_info": {
                    "duration_seconds": real_result["video_info"]["duration_seconds"],
                    "total_frames": real_result["video_info"]["total_frames"],
                    "fps": real_result["video_info"]["fps"],
                    "resolution": real_result["video_info"]["resolution"]
                },
                "processing_stats": {
                    "processing_time_seconds": real_result["processing_summary"]["processing_time"],
                    "fps_processed": round(real_result["video_info"]["total_frames"] / real_result["processing_summary"]["processing_time"], 1),
                    "gpu_accelerated": GPU_AVAILABLE,
                    "detection_count": real_result["processing_summary"]["total_detections"]
                },
                "detections": real_result["detections"],
                "detection_summary": {
                    "total_detections": real_result["processing_summary"]["total_detections"],
                    "detection_types": real_result["processing_summary"]["detection_types"],
                    "average_confidence": real_result["processing_summary"].get("average_confidence", 0.0),
                    "gpu_performance": {
                        "gpu_type": "apple_m_series",
                        "expected_speedup": "3-5x vs CPU (Neural Engineä¼˜åŒ–)",
                        "memory_efficiency": "é«˜æ•ˆ (ç»Ÿä¸€å†…å­˜æ¶æ„)",
                        "backend": "coreml"
                    }
                }
            }
        }
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æœï¼Œè¿”å›å¤„ç†ä¸­çŠ¶æ€
    return {
        "success": True,
        "task_id": task_id,
        "status": "processing",
        "message": "è§†é¢‘å¤„ç†ä¸­...",
        "progress": 50,
        "result": None
    }

@app.get("/api/video/result/{task_id}")
async def get_video_result(task_id: str):
    """è·å–è§†é¢‘å¤„ç†çš„è¯¦ç»†ç»“æœ"""
    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„å¤„ç†ç»“æœ
    if task_id in processing_results:
        real_result = processing_results[task_id]
        
        # è¿”å›è¯¦ç»†ç»“æœæ•°æ®
        return {
            "success": True,
            "task_id": task_id,
            "result": {
                "success": True,
                "video_info": {
                    "duration_seconds": real_result["video_info"]["duration_seconds"],
                    "total_frames": real_result["video_info"]["total_frames"],
                    "fps": real_result["video_info"]["fps"],
                    "resolution": real_result["video_info"]["resolution"]
                },
                "processing_stats": {
                    "processing_time_seconds": real_result["processing_summary"]["processing_time"],
                    "fps_processed": round(real_result["video_info"]["total_frames"] / real_result["processing_summary"]["processing_time"], 1),
                    "gpu_accelerated": GPU_AVAILABLE,
                    "detection_count": real_result["processing_summary"]["total_detections"]
                },
                "detections": real_result["detections"],
                "detection_summary": {
                    "total_detections": real_result["processing_summary"]["total_detections"],
                    "detection_types": real_result["processing_summary"]["detection_types"],
                    "average_confidence": real_result["processing_summary"].get("average_confidence", 0.0),
                    "gpu_performance": {
                        "gpu_type": "apple_m_series",
                        "expected_speedup": "3-5x vs CPU (Neural Engineä¼˜åŒ–)",
                        "memory_efficiency": "é«˜æ•ˆ (ç»Ÿä¸€å†…å­˜æ¶æ„)",
                        "backend": "coreml"
                    }
                }
            }
        }
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æœï¼Œè¿”å›é”™è¯¯
    return {
        "success": False,
        "task_id": task_id,
        "error": "ç»“æœä¸å­˜åœ¨æˆ–ä»»åŠ¡æœªå®Œæˆ"
    }

if __name__ == "__main__":
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    print("ğŸš€ åº·å…»AIæ£€æµ‹ç³»ç»Ÿ - è¾¹ç¼˜æ§åˆ¶å™¨ (ç®€åŒ–ç‰ˆ)")
    print("=" * 60)
    print("ğŸ“Š GPUæ”¯æŒ:", "âœ… å¯ç”¨" if GPU_AVAILABLE else "âŒ ç¦ç”¨")
    print("ğŸŒ æœåŠ¡ç«¯å£: 8084")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8084/docs")
    print("=" * 60)
    
    # å¦‚æœGPUæ£€æµ‹å¯ç”¨ï¼Œæ˜¾ç¤ºGPUä¿¡æ¯
    if GPU_AVAILABLE:
        try:
            gpu_detector = get_gpu_detector()
            gpu_info = gpu_detector.get_gpu_info()
            print(f"ğŸ”¥ æ£€æµ‹åˆ°GPU: {gpu_info['gpu_type']} - {gpu_info['gpu_name']}")
            print(f"âš¡ ä¼˜åŒ–åç«¯: {gpu_info['optimization_backend']}")
        except Exception as e:
            print(f"âš ï¸  GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
    
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8084,
        access_log=True
    )