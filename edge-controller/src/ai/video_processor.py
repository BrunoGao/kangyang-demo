#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘æ–‡ä»¶å¤„ç†å™¨ - ç”¨äºæµ‹è¯•è·Œå€’æ£€æµ‹ç®—æ³•
æ”¯æŒMP4ã€AVIç­‰è§†é¢‘æ–‡ä»¶çš„å¤„ç†å’Œæ£€æµ‹
"""

import cv2
import numpy as np
import logging
import time
import asyncio
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime
import os
from pathlib import Path

from .fall_detector import FallDetector
from .fire_detector import FireDetector  
from .smoke_detector import SmokeDetector
from .gpu_optimized_detector import GPUAdaptiveDetectorFactory
from core.gpu_detector import get_gpu_detector

logger = logging.getLogger(__name__)

class VideoProcessor:
    """è§†é¢‘æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
        
        Args:
            config: å¤„ç†é…ç½®å‚æ•°
        """
        self.config = config or {}
        
        # GPUæ£€æµ‹å’Œä¼˜åŒ–
        self.gpu_detector = get_gpu_detector()
        self.gpu_info = self.gpu_detector.get_gpu_info()
        self.recommended_settings = self.gpu_detector.get_recommended_settings()
        
        logger.info(f"ğŸ”¥ GPUæ£€æµ‹ç»“æœ: {self.gpu_info['gpu_type']} - {self.gpu_info['gpu_name']}")
        logger.info(f"ğŸš€ ä¼˜åŒ–åç«¯: {self.gpu_info['optimization_backend']}")
        
        # ä½¿ç”¨GPUä¼˜åŒ–çš„æ£€æµ‹å™¨
        try:
            self.fall_detector = GPUAdaptiveDetectorFactory.create_fall_detector(
                self.config.get("fall_detection", {})
            )
            logger.info("âœ… GPUä¼˜åŒ–è·Œå€’æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"GPUä¼˜åŒ–æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ£€æµ‹å™¨: {e}")
            # å›é€€åˆ°ä¼ ç»Ÿæ£€æµ‹å™¨
            self.fall_detector = FallDetector(self.config.get("fall_detection", {}))
        
        try:
            self.fire_detector = GPUAdaptiveDetectorFactory.create_fire_detector(
                self.config.get("fire_detection", {})
            )
            logger.info("âœ… GPUä¼˜åŒ–ç«ç„°æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"GPUä¼˜åŒ–ç«ç„°æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ£€æµ‹å™¨: {e}")
            self.fire_detector = FireDetector(self.config.get("fire_detection", {}))
            
        try:
            self.smoke_detector = GPUAdaptiveDetectorFactory.create_smoke_detector(
                self.config.get("smoke_detection", {})
            )
            logger.info("âœ… GPUä¼˜åŒ–çƒŸé›¾æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"GPUä¼˜åŒ–çƒŸé›¾æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ£€æµ‹å™¨: {e}")
            self.smoke_detector = SmokeDetector(self.config.get("smoke_detection", {}))
        
        # å¤„ç†å‚æ•° - ä½¿ç”¨GPUä¼˜åŒ–è®¾ç½®
        self.fps_limit = self.config.get("fps_limit", 30)
        self.skip_frames = self.config.get("skip_frames", 0)
        
        # ä½¿ç”¨GPUæ¨èçš„è¾“å…¥å°ºå¯¸
        recommended_size = self.recommended_settings['input_size']
        self.resize_width = self.config.get("resize_width", recommended_size[0])
        self.resize_height = self.config.get("resize_height", recommended_size[1])
        
        # GPUä¼˜åŒ–å‚æ•°
        self.batch_size = self.recommended_settings.get('batch_size', 1)
        self.use_fp16 = self.recommended_settings.get('use_fp16', False)
        self.num_threads = self.recommended_settings.get('num_threads', 4)
        
        logger.info(f"ğŸ“ å¤„ç†å°ºå¯¸: {self.resize_width}x{self.resize_height}")
        logger.info(f"âš¡ æ‰¹å¤„ç†å¤§å°: {self.batch_size}, FP16: {self.use_fp16}")
        logger.info(f"ğŸ§µ çº¿ç¨‹æ•°: {self.num_threads}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_frames": 0,
            "processed_frames": 0,
            "detections": [],
            "processing_time": 0,
            "start_time": None,
            "end_time": None
        }
        
        logger.info("è§†é¢‘å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_video_file(self, video_path: str) -> Dict[str, Any]:
        """éªŒè¯è§†é¢‘æ–‡ä»¶"""
        try:
            if not os.path.exists(video_path):
                return {"valid": False, "error": "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"}
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return {"valid": False, "error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}
            
            # è·å–è§†é¢‘ä¿¡æ¯
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = total_frames / fps if fps > 0 else 0
            
            cap.release()
            
            return {
                "valid": True,
                "total_frames": total_frames,
                "fps": fps,
                "width": width,
                "height": height,
                "duration_seconds": duration,
                "file_size": os.path.getsize(video_path)
            }
            
        except Exception as e:
            logger.error(f"éªŒè¯è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            return {"valid": False, "error": str(e)}
    
    async def process_video(self, video_path: str, 
                           algorithms: List[str] = None,
                           progress_callback: Callable = None) -> Dict[str, Any]:
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œæ‰§è¡Œè·Œå€’æ£€æµ‹
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            algorithms: è¦å¯ç”¨çš„ç®—æ³•åˆ—è¡¨ ['fall_detection', 'fire_detection', 'smoke_detection']
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # é»˜è®¤å¯ç”¨è·Œå€’æ£€æµ‹
            if algorithms is None:
                algorithms = ['fall_detection']
            
            # éªŒè¯è§†é¢‘æ–‡ä»¶
            validation = self.validate_video_file(video_path)
            if not validation["valid"]:
                return {"success": False, "error": validation["error"]}
            
            logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
            logger.info(f"è§†é¢‘ä¿¡æ¯: {validation}")
            
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self.stats = {
                "total_frames": validation["total_frames"],
                "processed_frames": 0,
                "detections": [],
                "processing_time": 0,
                "start_time": datetime.now(),
                "end_time": None,
                "video_info": validation
            }
            
            # æ‰“å¼€è§†é¢‘
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return {"success": False, "error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}
            
            frame_number = 0
            detection_count = 0
            start_time = time.time()
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_number += 1
                current_time = time.time()
                
                # è·³å¸§å¤„ç†
                if self.skip_frames > 0 and frame_number % (self.skip_frames + 1) != 0:
                    continue
                
                # ç¼©æ”¾å¤„ç†
                if self.resize_width and self.resize_height:
                    frame = cv2.resize(frame, (self.resize_width, self.resize_height))
                
                # æ‰§è¡Œæ£€æµ‹
                detections = await self._run_detections(frame, current_time, frame_number, algorithms)
                
                if detections:
                    detection_count += len(detections)
                    self.stats["detections"].extend(detections)
                    
                    # è®°å½•æ£€æµ‹ç»“æœ
                    for detection in detections:
                        logger.info(f"æ£€æµ‹åˆ°{detection['type']}: ç½®ä¿¡åº¦={detection['confidence']:.2f}, å¸§å·={frame_number}")
                
                self.stats["processed_frames"] += 1
                
                # è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress = self.stats["processed_frames"] / validation["total_frames"]
                    await progress_callback(progress, frame_number, detections)
                
                # FPSé™åˆ¶
                if self.fps_limit > 0:
                    frame_time = 1.0 / self.fps_limit
                    elapsed = time.time() - current_time
                    if elapsed < frame_time:
                        await asyncio.sleep(frame_time - elapsed)
            
            cap.release()
            
            # å®Œæˆç»Ÿè®¡
            end_time = time.time()
            self.stats["end_time"] = datetime.now()
            self.stats["processing_time"] = end_time - start_time
            
            # ç”Ÿæˆç»“æœæŠ¥å‘Š
            result = {
                "success": True,
                "video_path": video_path,
                "algorithms_used": algorithms,
                "processing_stats": {
                    "total_frames": validation["total_frames"],
                    "processed_frames": self.stats["processed_frames"],
                    "processing_time_seconds": self.stats["processing_time"],
                    "fps_processed": self.stats["processed_frames"] / self.stats["processing_time"],
                    "detection_count": detection_count
                },
                "detections": self.stats["detections"],
                "detection_summary": self._generate_detection_summary()
            }
            
            logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {result['processing_stats']}")
            return result
            
        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def _run_detections(self, frame: np.ndarray, timestamp: float, 
                            frame_number: int, algorithms: List[str]) -> List[Dict[str, Any]]:
        """è¿è¡Œæ£€æµ‹ç®—æ³•"""
        detections = []
        
        try:
            # è·Œå€’æ£€æµ‹
            if 'fall_detection' in algorithms:
                fall_result = self.fall_detector.detect(frame, timestamp, frame_number)
                if fall_result:
                    detections.append(fall_result)
            
            # ç«ç„°æ£€æµ‹
            if 'fire_detection' in algorithms:
                fire_result = self.fire_detector.detect(frame, timestamp, frame_number)
                if fire_result:
                    detections.append(fire_result)
            
            # çƒŸé›¾æ£€æµ‹
            if 'smoke_detection' in algorithms:
                smoke_result = self.smoke_detector.detect(frame, timestamp, frame_number)
                if smoke_result:
                    detections.append(smoke_result)
            
        except Exception as e:
            logger.error(f"æ£€æµ‹ç®—æ³•æ‰§è¡Œå¼‚å¸¸: {e}")
        
        return detections
    
    def _generate_detection_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ£€æµ‹ç»“æœæ‘˜è¦"""
        try:
            detections = self.stats["detections"]
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            type_counts = {}
            confidence_by_type = {}
            
            for detection in detections:
                det_type = detection.get("type", "unknown")
                
                if det_type not in type_counts:
                    type_counts[det_type] = 0
                    confidence_by_type[det_type] = []
                
                type_counts[det_type] += 1
                confidence_by_type[det_type].append(detection.get("confidence", 0))
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            summary = {
                "total_detections": len(detections),
                "detection_types": type_counts,
                "average_confidence_by_type": {},
                "max_confidence_by_type": {},
                "detection_timeline": []
            }
            
            # ç½®ä¿¡åº¦ç»Ÿè®¡
            for det_type, confidences in confidence_by_type.items():
                if confidences:
                    summary["average_confidence_by_type"][det_type] = sum(confidences) / len(confidences)
                    summary["max_confidence_by_type"][det_type] = max(confidences)
            
            # æ—¶é—´çº¿ï¼ˆå‰10ä¸ªæ£€æµ‹ï¼‰
            timeline = sorted(detections, key=lambda x: x.get("frame_number", 0))[:10]
            for detection in timeline:
                summary["detection_timeline"].append({
                    "frame_number": detection.get("frame_number"),
                    "timestamp": detection.get("timestamp"),
                    "type": detection.get("type"),
                    "confidence": detection.get("confidence"),
                    "subtype": detection.get("subtype")
                })
            
            return summary
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ£€æµ‹æ‘˜è¦å¼‚å¸¸: {e}")
            return {"error": str(e)}
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()